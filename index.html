<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="ali.css" type="text/css" />
<style>
#paper{color: #A52A2A}
#paperlink{color: #C0C0C0}
#papercode{color: #3CB371}
#paperdata{color: #FFA500}
#paperslides{color: #FF69B4}
#papercomments{width: 700px; font-family: Helvetica}
#paperabstract{width: 700px; font-size: 1}
#papertitle{width: 700px; font-size:3}
</style>
<title>Jian Liang</title>
<link rel="shortcut icon" href="assets/JL.ico" />
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>

<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="experience.html" class="current">Experience</a></div>
<div class="menu-item"><a href="education.html">Education</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="activity.html">Activities</a></div>
<div class="menu-item"><a href="miscellaneous.html">Miscellaneous</a></div>
<div class="menu-item"><a href="deadlines.html">Deadlines</a></div>
</td>
<td id="layout-content">
<h1>About Me</h1>
<p><div><img src="assets/liangjian@sigir.jpg" alt="Jian Liang" style="float:left" hspace="10" width="200" height="280"></div> 
</p>
<p>
<font size="4"><b>梁坚 (Jian Liang, Tim)</b></font><br />
Associate Professor<br />
Center for Research on Intelligent Perception and Computing<br />
Institute of Automation, Chinese Academy of Sciences<br /><br />
Room 1505, Intelligent Building, 95 Zhongguancun East Road<br />
100190, Haidian District, Beijing, China<br><br>
<font size='2'>&#x1F47B</font><a href="assets/liangjian-cv.pdf" target=&ldquo;blank&rdquo;>Resume</a><br />
<font size='4'>&#x265F</font><a href="https://github.com/tim-learn" target=&ldquo;blank&rdquo;>Github</a><br />
<font size='4'>&#x1F396</font><a href="https://scholar.google.com/citations?user=eY8i-mQAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a><br />
<font size='2'>&#x1F4C4</font><a href="https://arxiv.org/a/liang_j_1.html" target=&ldquo;blank&rdquo;>Arxiv</a><br />
&nbsp;<font size='2'>&#x21F0</font> <a href="mailto:liangjian92@gmail.com" target=&ldquo;blank&rdquo;>liangjian92&#x1F300gmail.com</a> or <a href="mailto:jian.liang@nlpr.ia.ac.cn" target=&ldquo;blank&rdquo;>jian.liang&#x1F300nlpr.ia.ac.cn</a>
</p>
<br />

<p>Before joining CASIA in June 2021, I was a research fellow at the Vision and Learning Group, National University of Singapore, working with <a href="https://sites.google.com/site/jshfeng/">Dr. Jiashi Feng</a> from June 2019 to April 2021.
I obtained Ph.D. in <i>Pattern Recognition and Intelligent Systems</i> from CASIA in Jan 2019, under the supervision of <a href="http://cripac.ia.ac.cn/en/EN/column/item80.shtml">Prof. Tieniu Tan</a> and co-supervision of <a href="http://people.ucas.ac.cn/~heran">Prof. Ran He</a> and <a href="http://cripac.ia.ac.cn/en/EN/column/item110.shtml">Prof. Zhenan Sun</a>, and received my bachelor degree in <i>Automation</i> from Xi'an Jiaotong University in June 2013.</p>
<p>My current research interests mainly focus on representation learning, knowledge transfer, trustworthy AI (including security, privacy, or robustness in AI), and their applications in various computer vision problems.</p>
<!-- <ul>
<li>domain adaptation, model adaptation, test-time adaptation</li>
<li>non-iid federated learning, personalized federated learning</li>
<li>model attacks</li>
<li>open-world learning</li>
<li>face-related applications, deepfake detection</li>
</ul> -->

<div class="infoblock">
<div class="blockcontent">
<p><p style="text-align:center;"><i>
I am open to discussion or collaboration. Feel free to drop me an email if you're interested.
</i></p></p>
</div></div>

<h1>News</h1>
<ul>
<li><p>2023/11/16 Our paper on heterogeneous federated learning has been accepted to IEEE TPAMI (IF: 24.3).</p></li>
<li><p>2023/10/28 Two papers on model selection and uncertainty estimation in unsupervised domain adaptation have been accepted to NeurIPS DistShift Workshop 2023.</p></li>
<li><p>2023/09/22 Our paper on validation of unsupervised domain adaptation methods has been accepted to NeurIPS 2023.</p></li>
<li><p>2023/08/04 <a href="https://github.com/YuheD/ProxyMix">ProxyMix (source-free domain adaptation)</a> has been accepted to Neural Networks (IF: 7.8).</p></li>
<li><p>2023/07/14 Four papers have been accepted to ICCV 2023.</p></li>
<li><p>2023/07/04 <a href="https://github.com/yuyongcan/Benchmark-TTA">Benchmark-TTA</a> (a benchmark for test-time adaptation) has been released.</p></li>
<li><p>2023/07/02 <a href="https://github.com/YuheD/MAPS">MAPS (source-free domain adaptive keypoint detection)</a> has been accepted to IEEE TCSVT (IF: 8.4).</p></li>
</ul>
<br>

<h1>Recent Work</h1>
<details><summary>
<span id="papertitle">A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts.
</span></a><br></summary>
</details>

<b>Jian Liang</b>, Ran He, Tieniu Tan.<br>
<i>Arxiv technical report, 2023.</i><br>
[<a href="https://arxiv.org/pdf/2303.15361.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/tim-learn/awesome-test-time-adaptation"><span id="papercode">Code</span></a>]
<br><br>

<details><summary>
<span id="papertitle">Towards Realistic Unsupervised Fine-tuning with CLIP.
</span></a><br></summary>
<div id="abstract"><i>
Abstract: 
</i></div></details>

<b>Jian Liang</b>, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan.<br>
<i>Arxiv technical report, 2023.</i><br>
[<a href="https://arxiv.org/pdf/2308.12919.pdf"><span id="paper">Paper</span></a>]
<!-- [<a href="https://github.com/tim-learn/UEO"><span id="papercode">Code</span></a>] -->
<br><br>

<details><summary>
<span id="papertitle">Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification.
</span></a><br></summary>
</details>

Yongcan Yu, Lijun Sheng, Ran He, <b>Jian Liang</b>.<br>
<i>Arxiv technical report, 2023.</i><br>
[<a href="https://arxiv.org/pdf/2307.03133.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/yuyongcan/Benchmark-TTA"><span id="papercode">Code</span></a>]
<br><br>


<details><summary>
<span id="papertitle">Mixed Samples as Probes for Unsupervised Model Selection in Domain Adaptation.
</span></a><br></summary>
</details>

Dapeng Hu, <b>Jian Liang</b>, Jun Hao Liew, Chuhui Xue, Song Bai, Xinchao Wang.<br>
<i>Annual Conference on Neural Information Processing Systems (NeurIPS), 2023.</i><br>
[<a href="https://openreview.net/pdf?id=ackajXqei2"><span id="paper">Paper</span></a>]
[<a href="https://github.com/LHXXHB/MixVal"><span id="papercode">Code</span></a>]
<br><br>


<details><summary>
<span id="papertitle">AdaptGuard: Defending Against Universal Attacks for Model Adaptation.
</span></a><br></summary>
</details>

Lijun Sheng, <b>Jian Liang</b>, Ran He, Zilei Wang, Tieniu Tan.<br>
<i>International Conference on Computer Vision (ICCV), 2023.</i><br>
[<a href="https://arxiv.org/pdf/2303.10594.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/TomSheng21/AdaptGuard"><span id="papercode">Code</span></a>]
<br><br>

<details><summary>
<span id="papertitle">Improving Zero-Shot Generalization for CLIP with Synthesized Prompts.
</span></a><br></summary>
</details>

Zhengbo Wang, <b>Jian Liang</b>, Ran He, Nan Xu, Zilei Wang, Tieniu Tan.<br>
<i>International Conference on Computer Vision (ICCV), 2023.</i><br>
[<a href="https://arxiv.org/pdf/2307.07397.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/mrflogs/SHIP"><span id="papercode">Code</span></a>]
<br><br>

<details><summary>
<span id="papertitle">TALL: Thumbnail Layout for Deepfake Video Detection.
</span></a><br></summary>
</details>

Yuting Xu, <b>Jian Liang</b>, Ziming Yang, Gengyun Jia, Yanhao Zhang, Ran He.<br>
<i>International Conference on Computer Vision (ICCV), 2023.</i><br>
[<a href="https://arxiv.org/pdf/2307.07494.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/rainy-xu/TALL4Deepfake"><span id="papercode">Code</span></a>]
<br><br>

<details><summary>
<span id="papertitle">Informative Data Mining for One-shot Cross-Domain Semantic Segmentation.
</span></a><br></summary>
</details>

Yuxi Wang, <b>Jian Liang</b>, Yuran Yang, Zhaoxiang Zhang.<br>
<i>International Conference on Computer Vision (ICCV), 2023.</i><br>
[<a href="https://arxiv.org/pdf/2309.14241.pdf"><span id="paper">Paper</span></a>]
[<a href="https://github.com/yxiwang/IDM"><span id="papercode">Code</span></a>]
<br><br>

<h1>Group</h1>
<!-- Trustworthy and Intelligent Machines (TIM) Group -->
<h3>Current Students</h3>
<ul>
<li>
  <p><a href="https://tomsheng21.github.io/">Lijun Sheng</a> (with Prof. Tan),  Jiyang Guan (with Prof. He)</p>
</li>
<li>
  <p><a href="https://scholar.google.com/citations?user=uLBdZHYAAAAJ&hl=en">Yuhe Ding</a> (with Prof. Jiang),  <a href="https://scholar.google.com/citations?user=UX0kWkkAAAAJ&hl=en"> Aijing Yu</a> (with Prof. Zhang)</p>
</li>
<li>
	<p>Zhengbo Wang (with Prof. Tan), <a href="https://scholar.google.com/citations?user=_lMCBnoAAAAJ&hl=en">Yuting Xu</a> (with Prof. Zhang)</p>
</li>
<li>
	<p>Yanbo Wang (with Prof. He)</p>
</li>
<li>
	<p>Puning Yang (with Prof. He)</p>
</li>
<li>
	<p>Yongcan Yu, Kuangpo Guo (with Prof. Tan), Yingsheng Wang (with Prof. He)</p>
</li>
<li>
	<p>Shuo Lu, Xiaokun Yang (with Prof. Tan)</p>
</li>
<li>
	<p>Zixi Zhu (Intern)</p>
</li>
</ul>

<h3>Alumni (Since 2019)</h3>
<ul>
<li><p><a href="https://lhxxhb.github.io/">Dapeng Hu</a>, Research Scientist @ A*STAR</p></li>
<li><p><a href="https://yujun-shi.github.io/">Yujun Shi</a>, PhD @ NUS</p></li>
<li><p><a href="https://luomi97.github.io/">Mi Luo</a>, PhD @ UT Austin</p></li>
<li><p><a href="https://sites.google.com/view/yifan-zhang/">Yifan Zhang</a>, PhD @ NUS</p></li>
<li><p><a href="https://scholar.google.com/citations?user=XH_9XiMAAAAJ&hl=en">Lingxiao He</a>, Research Scientist @ JD</p></li>
<li><p><a herf="https://scholar.google.com/citations?user=ssNoKMAAAAAJ&hl=en">Yunbo Wang</a>, Assistant Professor @ CSU</p></li>
<li><p><a href="https://scholar.google.com/citations?user=sAfqGvwAAAAJ&hl=en">Boqiang Xu</a>, Postdoc @ NUS</p></li>
<li><p><a href="https://scholar.google.com/citations?user=waLCodcAAAAJ&hl=en">Yuxi Wang</a>, Assistant Professor @ HKISI, CAS</p></li>
<li><p><a href="https://samyu0304.github.io/">Junchi Yu</a>, PhD @ CASIA</p></li>
<li><p><a href="https://yfzhang114.github.io/">Yi-Fan Zhang</a>, PhD @ CASIA</p></li>
<li><p>Ziming Yang, PRC MFA</p></li>
<li><p><a href="https://scholar.google.com/citations?user=zJPp2fYAAAAJ&hl=en">Kekai Sheng</a>, Research Scientist @ Momenta</p></li>
</ul>
<br>

<br>
<div id="footer">
<div id="footer-text">
Last updated on Nov 27th, 2023. The CSS file is adapted from <a href="https://people.eecs.berkeley.edu/~brecht/" target="blank">Ben Recht's webpage</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
